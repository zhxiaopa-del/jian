[llm]
#model = "qwen-flash"
#model = "claude-3.5-sonnet-v2"
#model = "gpt4o"
#model = "llama3-2-90b-instruct-v1:0"
model = "qwen3-14b"
#api_key = "sk-ecaa2eedbec749ceb95d9a208d5a3972"
api_key="222442bb160d5081b9e38506901d6889"
#base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
#base_url = "http://localhost:4000/v1/chat/completions"
base_url="http://10.3.0.16:8100/v1"

max_tokens = 4096
#max_tokens = 4096
temperature = 0.2

[chunking]
chunk_size = 100  # Number of words per chunk
overlap = 40      # Number of words to overlap between chunks

[standardization]
enabled = false             # Whether to enable entity standardization
use_llm_for_entities = false  # Whether to use LLM for additional entity resolution

[inference]
enabled = true             # Whether to enable relationship inference
use_llm_for_inference = true  # Whether to use LLM for relationship inference
apply_transitive = true    # Whether to apply transitive inference rules
apply_lexical_similarity = true #后面俩关掉后 Distmult模型训练效果不好

[visualization]
edge_smooth = false
