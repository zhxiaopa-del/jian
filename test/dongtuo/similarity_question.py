import httpx

# é…ç½®ä¿¡æ¯
API_KEY = "ragflow-KCWP6wRAaUnjB1jdIGCWH4J5W1KOEYvwgSOjzgcpATE"
BASE_URL = "http://10.3.0.16:8080"
DEFAULT_DATASET_ID = "290db77ceac211f0be558281f8988170"

def retrieve_similar_topk(
    question: str,
    dataset_id: str = DEFAULT_DATASET_ID,
    top_k: int = 3,
    similarity_threshold: float = 0.2,
) -> list:
    """æ ¹æ®é—®é¢˜åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­åšç›¸ä¼¼æ€§æ£€ç´¢ï¼Œè¿”å›åŒ…å«â€˜é—®é¢˜â€™å’Œâ€˜ç­”æ¡ˆâ€™çš„åŸå§‹åˆ‡ç‰‡ã€‚"""
    url = f"{BASE_URL.rstrip('/')}/api/v1/retrieval"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}",
    }
    payload = {
        "question": question,
        "dataset_ids": [str(dataset_id)],
        "top_k": max(top_k, 20),
        "similarity_threshold": similarity_threshold,
        "page_size": top_k,
    }
    with httpx.Client(timeout=30) as client:
        resp = client.post(url, json=payload, headers=headers)
        resp.raise_for_status()
        result = resp.json()

    if result.get("code") != 0:
        raise RuntimeError(result.get("message", result))

    data = result.get("data") or {}
    chunks = data.get("chunks", []) if isinstance(data, dict) else []
    
    # æŒ‰ç…§ç›¸ä¼¼åº¦æ’åº
    by_sim = sorted(
        chunks,
        key=lambda x: float(x.get("similarity") or x.get("vector_similarity") or 0),
        reverse=True,
    )
    return by_sim[:top_k]


def get_chunk_question(item: dict) -> str:
    """ä» RAGFlow è¿”å›çš„ chunk ä¸­æå– Question å­—æ®µã€‚å…¼å®¹ question_kwd / question / questions ç­‰ã€‚"""
    q = item.get("question_kwd") or item.get("question") or item.get("chunk_question")
    if q and isinstance(q, str):
        return q.strip()
    questions = item.get("questions")
    if isinstance(questions, list) and questions:
        first = questions[0]
        return (first.strip() if isinstance(first, str) else str(first)) if first else ""
    return "ï¼ˆè¯¥åˆ‡ç‰‡æœªå•ç‹¬å­˜å‚¨é—®é¢˜å­—æ®µï¼‰"


def get_top_similar_questions(question: str, top_k: int = 3, dataset_id: str = DEFAULT_DATASET_ID) -> list[str]:
    """æ ¹æ®ç”¨æˆ·é—®é¢˜æ£€ç´¢ç›¸ä¼¼åº¦æœ€é«˜çš„ top_k ä¸ªåˆ‡ç‰‡ï¼Œä»…è¿”å›æ¯ä¸ªåˆ‡ç‰‡çš„ Question åˆ—è¡¨ã€‚"""
    rows = retrieve_similar_topk(question, dataset_id=dataset_id, top_k=top_k)
    return [get_chunk_question(item) for item in rows]


def run_retrieve_top3(question: str, top_k: int = 3):
    """æå–å¹¶è¾“å‡º TopK æ£€ç´¢ç»“æœä¸­å­˜å‚¨çš„â€˜ç›¸ä¼¼é—®é¢˜â€™ã€‚"""
    print(f"ğŸ” æ­£åœ¨æ£€ç´¢ä¸â€œ{question}â€ç›¸ä¼¼çš„é—®é¢˜...\n")

    try:
        rows = retrieve_similar_topk(question, top_k=top_k)
    except Exception as e:
        print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
        return

    if not rows:
        print("æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚")
        return

    print("=" * 80)
    for i, item in enumerate(rows, 1):
        # --- å…³é”®æå–é€»è¾‘ ---
        # RAGFlow çš„ QA æ¨¡å¼é€šå¸¸å°†é—®é¢˜å­˜åœ¨ 'question_kwd' æˆ– 'question' å­—æ®µä¸­
        print(item)
        print("-" * 80)
        matched_question = item.get("question_kwd") or item.get("question") or "ï¼ˆè¯¥åˆ‡ç‰‡æœªå•ç‹¬å­˜å‚¨é—®é¢˜å­—æ®µï¼‰"
        
        # è·å–åˆ‡ç‰‡æ­£æ–‡å†…å®¹ï¼ˆç­”æ¡ˆéƒ¨åˆ†ï¼‰
        content = item.get("content_with_weight") or item.get("content") or "æ— å†…å®¹"
        
        # è·å–ç›¸å…³å…ƒæ•°æ®
        doc_name = item.get("document_keyword") or item.get("docnm_kwd") or "æœªçŸ¥æ–‡æ¡£"
        sim = item.get("similarity") or item.get("vector_similarity")
        sim_str = f"{sim:.4f}" if sim is not None else "-"

        print(f"ã€Top {i}ã€‘ åŒ¹é…å¾—åˆ†: {sim_str} | æ¥æºæ–‡æ¡£: {doc_name}")
        print(f"ğŸ“Œ æ£€ç´¢åˆ°çš„åŸé—®é¢˜: {matched_question}")
        print(f"ğŸ’¡ å¯¹åº”åˆ‡ç‰‡å†…å®¹: {content.strip()}")
        print("-" * 80)


if __name__ == "__main__":
    # æ‰§è¡Œæ£€ç´¢
    TOP_K = 3
    QUESTION = "ç…¤çŸ¿ä¼ä¸šå¦‚ä½•ä¿éšœä»ä¸šäººå‘˜åœ¨å®‰å…¨ç”Ÿäº§ä¸èŒä¸šç—…å±å®³é˜²æ²»ä¸­çš„ç›‘ç£æƒåˆ©ï¼Ÿ"
    run_retrieve_top3(question=QUESTION, top_k=TOP_K)